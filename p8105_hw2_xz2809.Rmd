---
title: "P8105_hw2_xz2809"
author: "Coco Zou"
date: "9/29/2018"
output: html_document
---

```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

Here is the **code chunk** to read the data
```{r}
NYCtransit_data <-  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

Now we are trying to clean the data: retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. 
```{r}
NYCtransit_data = janitor::clean_names(NYCtransit_data)
NYCtransit_data_retain = 
  select(NYCtransit_data,line:vending, ada, ada_notes) %>% 
  mutate(entry=recode(entry,'YES'=TRUE, 'NO'=FALSE)) 
```

This dataset contains line, station name, station latitude and longtitude, routes served, whether there is entry and exist and the type of the entry, and ADA compliance. I import the data and then clean the names into all lower cases. Then I select the only variable required, at last I converted the "entry" variable into logical variable "TRUE" and "FALSE". The diminsion of the given data is `r dim(NYCtransit_data_retain)`. This is not a tidy dataset yet, because the "route1" to "route11" are apparently data, but they appreared as variables at the first row. Therefore, we need do some reformatting later. 

```{r}
num_stations = 
  distinct(NYCtransit_data_retain, line, station_name) %>% 
  dim()

num_stations_ada = 
  filter(NYCtransit_data_retain, ada=='TRUE') %>% 
  distinct(line,station_name) %>% 
  dim()

a = filter(NYCtransit_data_retain,entry == 'TRUE')
length_1 = length(a$entry)
b = filter(NYCtransit_data_retain,entry == 'TRUE', vending=='YES')
length_2= length(b$entry)
proportion=length_2/length_1
```

Now we are trying to reformat the dataset 

```{r}
NYCtransit_data_retain %>% 
  gather(key = route_number, value = route_name, route1:route11) %>% 
  filter(route_name=='A') %>% 
  distinct(station_name) %>% 
  dim()

NYCtransit_data_retain %>% 
  gather(key = route_number, value = route_name, route1:route11) %>% 
  filter(route_name=='A',ada==TRUE) %>% 
  distinct(station_name) %>% 
  dim()
```

##Problem 2

Here is the **code chunk** to read and clean the data for mr trash wheel 
```{r}
trashwheel_data <-  
  read_excel( "data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",range = cell_cols("A:N"), ) %>% 
  janitor::clean_names() %>% 
  head(256) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Here is the **code chunk** to read and clean the data for mr trash wheel 
```{r}
precipitation_2016_data<-
  read_excel( "data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",sheet = "2016 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>%
  mutate(
    year = 2016
  )

precipitation_2017_data<-
  read_excel( "data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",sheet = "2017 Precipitation", range = "A2:B15") %>% 
  janitor::clean_names() %>%
  mutate(
    year = 2017
  )

combine_precipitation_data =
  left_join(precipitation_2016_data,precipitation_2017_data,by = "month") 

combine_precipitation_data$month = month.name[combine_precipitation_data$month]
```

##Problem 3

Here is the **code chunk** that loads the data for problem 3:
```{r}
library(p8105.datasets)
data("brfss_smart2010")
brfss_smart2010=
  janitor::clean_names(brfss_smart2010) %>% 
  select(-topic) %>% 
  select(-class) %>% 
  select(-question) %>% 
  select(-sample_size) %>%
  select(-(confidence_limit_low:geo_location))
```

Now we create a new variable showing the proportion of responses that were “Excellent” or “Very Good”:
```{r}
brfss_smart2010 %>% 
  filter(response=='Excellent' | response=='Very good') %>% 
  dim()

dim(brfss_smart2010)
```

```{r}
brfss_smart2010 %>% 
  distinct(locationabbr) %>% 
  dim()
```
The proportion of responses that were “Excellent” or “Very Good" is `r 4260/134203`.
In America, there are 50 states and every state has been represented. The one more variable is "DC", which is not an acutual state but the capital of USA.

```{r}
MaxTable <- function(x){
     m <- unique(x)
     m[which.max(tabulate(match(x,m)))]
}
MaxTable(brfss_smart2010$locationabbr)
```


```{r}
brfss_smart2010$data_value=as.numeric(brfss_smart2010$data_value)
brfss_excellent_2002 = 
  filter(brfss_smart2010,response=='Excellent') %>% 
  filter(year==2002)
summary(brfss_excellent_2002$data_value)
ggplot(brfss_excellent_2002,aes(x=data_value))+geom_histogram()
```

The most most observed state is NJ. The median of the “Excellent” response value is 23.60. 




